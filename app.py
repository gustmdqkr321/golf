# app.py
from pathlib import Path
import io
import pandas as pd
import streamlit as st
from core.loader import discover_sections

st.set_page_config(page_title="Modular Streamlit App", layout="wide")

# â”€â”€ í”„ë¡œì íŠ¸ ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).parent
SECTIONS_DIR = BASE_DIR / "sections"

# â”€â”€ ì½”ë“œ ë‚´ ë””í´íŠ¸ íŒŒì¼ ê²½ë¡œ(ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_CODE_DEFAULTS = True  # ì—…ë¡œë“œ ì—†ì„ ë•Œ ì½”ë“œ ë””í´íŠ¸ ì‚¬ìš© ì—¬ë¶€

# ë¬´ì§€ê°œ(ê¸°ì¡´) ì—‘ì…€
DEFAULT_PRO_PATH = "/Users/park_sh/Desktop/sim_pro/ë ˆí¼/test/rory.xlsx"
DEFAULT_AMA_PATH = "/Users/park_sh/Desktop/sim_pro/ë ˆí¼/test/hong.xlsx"

# GS CSV (í”„ë¡œ/ì¼ë°˜)
DEFAULT_GS_PRO_PATH = "/Users/park_sh/Desktop/sim_pro/ë ˆí¼/test/CsvExport_rory.csv"
DEFAULT_GS_AMA_PATH = "/Users/park_sh/Desktop/sim_pro/ë ˆí¼/test/CsvExport_hong.csv"

# â”€â”€ íŒŒì¼ ë¡œë” (xlsx/csv/xls/xlsb) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def read_xlsx_to_array(file_or_path):
    """
    - UploadedFile/BytesIO/Path ëª¨ë‘ ì§€ì›
    - ë°˜í™˜: numpy.ndarray (header=None)
    """
    name = getattr(file_or_path, "name", str(file_or_path))
    suffix = Path(name).suffix.lower()

    fobj = file_or_path
    if hasattr(file_or_path, "getvalue"):  # UploadedFile
        fobj = io.BytesIO(file_or_path.getvalue())

    try:
        if suffix in (".xlsx", ".xlsm", ".xltx", ".xltm"):
            try:
                import openpyxl  # noqa: F401
            except ImportError:
                st.error("`.xlsx`ë¥¼ ì½ìœ¼ë ¤ë©´ `openpyxl>=3.1.5`ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return None
            df = pd.read_excel(fobj, header=None, engine="openpyxl")

        elif suffix == ".csv":
            # CSVëŠ” êµ¬ë¶„ì ìë™ ê°ì§€ + python ì—”ì§„ + ê¹¨ì§„ ì¤„ì€ ê±´ë„ˆë›°ê¸°
            # (C ì—”ì§„ì€ ì—„ê²©í•´ì„œ "Expected 1 fields..." ê°™ì€ ì˜¤ë¥˜ê°€ ì˜ ë‚©ë‹ˆë‹¤)
            try:
                df = pd.read_csv(
                    fobj,
                    header=None,
                    sep=None,                # êµ¬ë¶„ì ìë™ ê°ì§€
                    engine="python",         # ìœ ì—°í•œ íŒŒì„œ
                    on_bad_lines="skip",     # ë¹„ì •ìƒ ë¼ì¸ì€ ê±´ë„ˆë›°ê¸°
                    skipinitialspace=True,   # êµ¬ë¶„ì ë’¤ ê³µë°± ë¬´ì‹œ
                    encoding_errors="ignore" # ê¹¨ì§„ ì¸ì½”ë”©ì€ ë¬´ì‹œ
                )
            except Exception:
                # ì¬ì‹œë„: í”í•œ êµ¬ë¶„ìë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
                if hasattr(fobj, "seek"):
                    fobj.seek(0)
                for sep_try in [",", ";", "\t", "|"]:
                    try:
                        df = pd.read_csv(
                            fobj,
                            header=None,
                            sep=sep_try,
                            engine="python",
                            on_bad_lines="skip",
                            skipinitialspace=True,
                            encoding_errors="ignore",
                        )
                        break
                    except Exception:
                        if hasattr(fobj, "seek"):
                            fobj.seek(0)
                else:
                    raise  # ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ ì›ë˜ ì˜ˆì™¸ ì˜¬ë¦¼


        elif suffix == ".xls":
            try:
                import xlrd  # noqa: F401
            except ImportError:
                st.error("`.xls`ë¥¼ ì½ìœ¼ë ¤ë©´ `xlrd<2.0`ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return None
            df = pd.read_excel(fobj, header=None, engine="xlrd")

        elif suffix == ".xlsb":
            try:
                import pyxlsb  # noqa: F401
            except ImportError:
                st.error("`.xlsb`ë¥¼ ì½ìœ¼ë ¤ë©´ `pyxlsb`ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return None
            df = pd.read_excel(fobj, header=None, engine="pyxlsb")

        else:
            st.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {suffix}")
            return None

        return df.values
    except Exception as e:
        st.exception(e)
        return None

def try_read_default(p: str | Path | None):
    if not p:
        return None, None
    p = Path(p).expanduser()
    if not p.exists():
        st.sidebar.warning(f"ë””í´íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {p}")
        return None, None
    try:
        return read_xlsx_to_array(p), p.name
    except Exception as e:
        st.sidebar.error(f"ë””í´íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {p} ({e})")
        return None, None

# â”€â”€ CSV ë¡œë”(DF ë°˜í™˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def read_csv_df_robust(file_or_path, header=None, **kwargs):
    fobj = file_or_path
    if hasattr(file_or_path, "getvalue"):
        fobj = io.BytesIO(file_or_path.getvalue())
    try:
        df = pd.read_csv(
            fobj,
            header=header,
            sep=None,
            engine="python",
            on_bad_lines="skip",
            skipinitialspace=True,
            encoding_errors="ignore",
            **kwargs,             # â† ì¶”ê°€
        )
        return df
    except Exception:
        if hasattr(fobj, "seek"): fobj.seek(0)
        for sep_try in [",", ";", "\t", "|"]:
            try:
                df = pd.read_csv(
                    fobj,
                    header=header,
                    sep=sep_try,
                    engine="python",
                    on_bad_lines="skip",
                    skipinitialspace=True,
                    encoding_errors="ignore",
                    **kwargs,         # â† ì¶”ê°€
                )
                return df
            except Exception:
                if hasattr(fobj, "seek"): fobj.seek(0)
        raise

def try_read_csv_default(p: str | Path | None):
    if not p:
        return None, None
    p = Path(p).expanduser()
    if not p.exists():
        st.sidebar.warning(f"GS ë””í´íŠ¸ CSVê°€ ì—†ìŠµë‹ˆë‹¤: {p}")
        return None, None
    try:
        return read_csv_df_robust(p, header=0), p.name
    except Exception as e:
        st.sidebar.error(f"GS CSV ì½ê¸° ì‹¤íŒ¨: {p} ({e})")
        return None, None
import io
import pandas as pd
import streamlit as st
# app.py ë“± ê³µìš© ë¡œë” íŒŒì¼ì— ë„£ìœ¼ì„¸ìš”
import io, csv, pandas as pd

def _sniff_csv(text: str):
    lines = text.splitlines()
    # 1) 'sep=,' ê°™ì€ ì—‘ì…€ í—¤ë” ì²˜ë¦¬
    for i, ln in enumerate(lines[:5]):
        low = ln.strip().lower()
        if low.startswith("sep=") and len(low) >= 5:
            sep = ln.strip()[4:5]
            return sep, i + 1  # ë‹¤ìŒ ì¤„ë¶€í„° ë°ì´í„°
    # 2) ê°€ì¥ ì•ˆì •ì ì¸ êµ¬ë¶„ì ì¶”ì •
    candidates = [",", ";", "\t", "|"]
    best_sep, best_score, start_row = ",", -1, 0
    for sep in candidates:
        counts = []
        for ln in lines:
            if not ln.strip():
                counts.append(0)
                continue
            counts.append(ln.count(sep))
        pos = [i for i, c in enumerate(counts) if c > 0]
        if not pos:
            continue
        sr = pos[0]
        avg = sum(counts[i] for i in pos) / len(pos)
        score = avg - 0.1 * sr
        if score > best_score:
            best_sep, best_score, start_row = sep, score, sr
    return best_sep, start_row

@st.cache_data(show_spinner=False)
def read_gs_csv_raw(file_or_path, sep: str | None = None) -> pd.DataFrame:
    """
    GS CSV â†’ DataFrame(ì—´ ì ˆëŒ€ ì‚­ì œ X, í–‰ ê¸¸ì´ íŒ¨ë”©ìœ¼ë¡œ ê· ì¼í™”)
    - êµ¬ë¶„ì sepì´ ì—†ìœ¼ë©´ ìë™ ìŠ¤ë‹ˆí•‘
    - 'sep=,' ë¼ì¸ ìë™ ë¬´ì‹œ
    - ëª¨ë“  í–‰ì„ 'ìµœëŒ€ ì—´ ìˆ˜'ë¡œ ë§ì¶”ì–´ ìš°ì¸¡ì„ "" ë¡œ íŒ¨ë”©
    """
    # 1) ë°”ì´íŠ¸ â†’ í…ìŠ¤íŠ¸
    if hasattr(file_or_path, "getvalue"):  # UploadedFile
        raw = file_or_path.getvalue()
    else:
        with open(file_or_path, "rb") as f:
            raw = f.read()
    try:
        text = raw.decode("utf-8-sig", errors="ignore")
    except Exception:
        text = raw.decode("utf-8", errors="ignore")

    # 2) êµ¬ë¶„ì/ì‹œì‘í–‰ ì¶”ì •
    sniffed_sep, start_row = _sniff_csv(text)
    use_sep = sep if sep else sniffed_sep

    # 3) csv.readerë¡œ ì§ì ‘ ì½ì–´ì„œ ëª¨ë“  í–‰ ê¸¸ì´ë¥¼ ë™ì¼í™”
    sio = io.StringIO(text)
    r = csv.reader(sio, delimiter=use_sep)
    all_rows = list(r)

    # header ì—†ëŠ” rawë¼ ê°€ì •í•˜ê³  start_rowë¶€í„° ë°ì´í„°
    data_rows = all_rows[start_row:]

    # ìµœëŒ€ ì—´ ìˆ˜
    max_len = max((len(row) for row in data_rows), default=0)

    # ìš°ì¸¡ íŒ¨ë”©(ë¹ˆ ì…€ ë³´ì¡´)
    for row in data_rows:
        if len(row) < max_len:
            row += [""] * (max_len - len(row))

    # 4) DataFrame í™” (ì ˆëŒ€ dropnaë¡œ ì—´ ì‚­ì œí•˜ì§€ ë§ ê²ƒ!)
    df = pd.DataFrame(data_rows, dtype=str)
    # í•„ìš”í•˜ë‹¤ë©´ íŠ¸ë¦¬ë°ë§Œ
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    return df




def try_read_gs_default(p: str | Path | None, sep=","):
    if not p:
        return None, None
    p = Path(p).expanduser()
    if not p.exists():
        st.sidebar.warning(f"GS ë””í´íŠ¸ CSVê°€ ì—†ìŠµë‹ˆë‹¤: {p}")
        return None, None
    try:
        return read_gs_csv_raw(p, sep=sep), p.name
    except Exception as e:
        st.sidebar.error(f"GS CSV ì½ê¸° ì‹¤íŒ¨: {p} ({e})")
        return None, None


# â”€â”€ í—¤ë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ§© Modular Streamlit App")
st.caption("ë©”ì¸ì•±ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ â†’ ì„¹ì…˜ì— ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ â†’ ì„¹ì…˜ì´ ë¡œì§ì„ í˜¸ì¶œí•´ UI ë Œë”")

# â”€â”€ ì‚¬ì´ë“œë°” ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì—…ë¡œë“œ")
    pro_file = st.file_uploader("í”„ë¡œ ì—‘ì…€(.xlsx)", type=["xlsx"], key="pro_file")
    ama_file = st.file_uploader("ì¼ë°˜ ì—‘ì…€(.xlsx)", type=["xlsx"], key="ama_file")
    st.divider()
    gs_pro_file = st.file_uploader("í”„ë¡œ GS(.csv)", type=["csv"], key="gs_pro_file")
    gs_ama_file = st.file_uploader("ì¼ë°˜ GS(.csv)", type=["csv"], key="gs_ama_file")

# â”€â”€ íŒŒì¼ ì„ íƒ: ì—…ë¡œë“œ > ë””í´íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if pro_file:
    pro_arr = read_xlsx_to_array(pro_file)
    pro_name = pro_file.name
elif USE_CODE_DEFAULTS:
    pro_arr, pro_name = try_read_default(DEFAULT_PRO_PATH)
else:
    pro_arr, pro_name = None, None

if ama_file:
    ama_arr = read_xlsx_to_array(ama_file)
    ama_name = ama_file.name
elif USE_CODE_DEFAULTS:
    ama_arr, ama_name = try_read_default(DEFAULT_AMA_PATH)
else:
    ama_arr, ama_name = None, None

# GS (csv) â€” DataFrameìœ¼ë¡œ, header=None
if gs_pro_file:
    gs_pro_arr = read_gs_csv_raw(gs_pro_file, sep=",")   # í•„ìš”í•˜ë©´ sep=";"ë¡œ
    gs_pro_name = gs_pro_file.name
elif USE_CODE_DEFAULTS:
    gs_pro_arr, gs_pro_name = try_read_gs_default(DEFAULT_GS_PRO_PATH, sep=",")
else:
    gs_pro_arr, gs_pro_name = None, None

if gs_ama_file:
    gs_ama_arr = read_gs_csv_raw(gs_ama_file, sep=",")
    gs_ama_name = gs_ama_file.name
elif USE_CODE_DEFAULTS:
    gs_ama_arr, gs_ama_name = try_read_gs_default(DEFAULT_GS_AMA_PATH, sep=",")
else:
    gs_ama_arr, gs_ama_name = None, None



# â”€â”€ ì»¨í…ìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ctx = {
    "pro_arr": pro_arr,
    "ama_arr": ama_arr,
    "gs_pro_arr": gs_pro_arr,
    "gs_ama_arr": gs_ama_arr,
    "files": {
        "pro_name": pro_name,
        "ama_name": ama_name,
        "gs_pro_name": gs_pro_name,
        "gs_ama_name": gs_ama_name,
    },
}

# â”€â”€ ì„¹ì…˜ ê²€ìƒ‰/ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sections = discover_sections(SECTIONS_DIR)
if not sections:
    st.warning("ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. sections/ ì•„ë˜ì— í´ë”ì™€ main.pyë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

sections_sorted = sorted(
    sections,
    key=lambda s: s["meta"].get("title", s["id"])   # íƒ€ì´í‹€ ê¸°ì¤€ ì •ë ¬
)

choices = {
    f"{s['meta'].get('title', s['id'])}": s
    for i, s in enumerate(sections_sorted)
}

labels = list(choices.keys())

# ì¿¼ë¦¬íŒŒë¼ë¯¸í„° ìœ ì§€
qp = st.query_params
current_id = qp.get("section")
default_label = next((lbl for lbl, sec in choices.items() if sec["id"] == current_id), labels[0])

with st.sidebar:
    st.header("ì„¹ì…˜")
    picked_label = st.selectbox("ì´ë™", options=labels, index=labels.index(default_label), key="section_select")

selected = choices[picked_label]
st.query_params["section"] = selected["id"]  # URL ë™ê¸°í™”

# â”€â”€ ì„¹ì…˜ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import inspect

run_fn = selected.get("run")
if callable(run_fn):
    sig = inspect.signature(run_fn)
    try:
        # run(ctx) ì§€ì›ì´ë©´ ctx ì „ë‹¬, ì•„ë‹ˆë©´ ì¸ì ì—†ì´
        if len(sig.parameters) >= 1:
            run_fn(ctx)
        else:
            run_fn()
    except TypeError as e:
        # ì •ë§ë¡œ ì¸ì ë¶ˆì¼ì¹˜ë¡œ ì‹¤íŒ¨í–ˆê³ , íŒŒë¼ë¯¸í„°ê°€ 0ê°œì¼ ë•Œë§Œ run() ì¬ì‹œë„
        if len(sig.parameters) == 0:
            run_fn()
        else:
            st.error("ì„¹ì…˜ ì‹¤í–‰ ì¤‘ TypeErrorê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ìƒì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            st.exception(e)
            st.stop()
    except Exception as e:
        st.error("ì„¹ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ìƒì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.exception(e)
        st.stop()
else:
    st.error("ì„ íƒí•œ ì„¹ì…˜ì— run í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€ ìƒíƒœ ì•ˆë‚´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    if pro_arr is None or ama_arr is None:
        st.info("ë¬´ì§€ê°œ(ê¸°ì¡´) ì—‘ì…€: ì—…ë¡œë“œ ë˜ëŠ” ë””í´íŠ¸ ì¤‘ í•˜ë‚˜ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.success(f"ì‚¬ìš© íŒŒì¼: í”„ë¡œ `{pro_name}` Â· ì¼ë°˜ `{ama_name}`")

    if gs_pro_arr is None or gs_ama_arr is None:
        st.info("GS CSV: ì—…ë¡œë“œí•˜ê±°ë‚˜ ë””í´íŠ¸ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    else:
        st.success(f"GS íŒŒì¼: í”„ë¡œ `{gs_pro_name}` Â· ì¼ë°˜ `{gs_ama_name}`")